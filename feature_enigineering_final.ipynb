{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scraped_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ab507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Property Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f95b9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the link column \n",
    "df = df.drop('Link', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2660960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the Not available with NaN\n",
    "df.replace(\"Not Available\", np.nan, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99193bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nan values\n",
    "# Check for NaN values in each column\n",
    "nan_counts_per_column = df.isna().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc567c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fill missing 'Age' values within each group\n",
    "def fill_age(group):\n",
    "    # Use the first non-NaN 'Age' value found in each group to fill the NaNs\n",
    "    return group.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Apply the function to each group for the 'Age' column\n",
    "grouped = df.groupby('Property Name')\n",
    "df['Age'] = grouped['Age'].transform(fill_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab951a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nan values\n",
    "# Check for NaN values in each column\n",
    "nan_counts_per_column = df.isna().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52abd4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PSF'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11096428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with no addresses\n",
    "df = df[df['Address'].notna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_bedroom(value):\n",
    "    # Convert NaN and float values to string to safely use string operations\n",
    "    value = str(value)\n",
    "        \n",
    "    # Handle 'Studio' entries\n",
    "    if 'Studio' in value:\n",
    "        return 1\n",
    "    # Handle entries like '3 bedroom (Dual Key)' and '2 bedroom (Dual Key)'\n",
    "    elif 'bedroom' in value:\n",
    "        return int(value.split()[0])\n",
    "    # Handle entries with '+' like '3+1'\n",
    "    elif '+' in value:\n",
    "        parts = value.split('+')\n",
    "        return sum(int(part) for part in parts if part.isdigit())\n",
    "    # Default case, check if it's a digit-only string and convert it to integer\n",
    "    elif value.isdigit():\n",
    "        return int(value)\n",
    "    # Return NaN for non-numeric or unexpected values to avoid data corruption\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply the function to the 'Bedrooms' column\n",
    "df['Bedrooms'] = df['Bedrooms'].apply(clean_bedroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b180333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_tenure(value):\n",
    "    # Check if the value is a string\n",
    "    if pd.isna(value):\n",
    "        return value  # Keep NaN as is or you can specify a default string if needed\n",
    "    value = str(value)  # Convert to string to ensure string operations can be applied\n",
    "\n",
    "    # Handle 'Freehold' entries\n",
    "    if 'freehold' in value.lower():\n",
    "        return '9999 years'\n",
    "    # Extract number of years from 'LEASEHOLD/...' or similar formats\n",
    "    elif 'leasehold/' in value.lower():\n",
    "        return value.split('/')[1].strip() + ' years'\n",
    "    # Handle specific year terms directly provided in the string\n",
    "    elif 'years' in value.lower():\n",
    "        # Try to find the number of years explicitly mentioned\n",
    "        import re\n",
    "        match = re.search(r'\\b(\\d+)\\s*years', value, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1) + ' years'\n",
    "    # Handle any remaining strings that may directly start with the number of years\n",
    "    else:\n",
    "        import re\n",
    "        match = re.search(r'^(\\d+)', value)\n",
    "        if match:\n",
    "            return match.group(1) + ' years'\n",
    "    # Return the original value if none of the above conditions are met\n",
    "    return value\n",
    "\n",
    "# Apply the function to the 'Tenure' column\n",
    "df['Tenure'] = df['Tenure'].apply(clean_tenure)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def clean_and_convert_tenure(value):\n",
    "    if pd.isna(value):\n",
    "        return value  # Return NaN as it is\n",
    "    value = str(value).lower()  # Convert to lowercase string for uniform processing\n",
    "    if 'years' in value:\n",
    "        value = value.replace('years', '').strip()  # Remove the word 'years'\n",
    "    if value.isdigit():\n",
    "        return int(value)  # Convert to integer\n",
    "    return value  # Return the original value if it's not a clean number\n",
    "\n",
    "# Apply the function to the 'Tenure' column to clean and convert it\n",
    "df['Tenure'] = df['Tenure'].apply(clean_and_convert_tenure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a256b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the new nan values\n",
    "nan_counts_per_column = df.isna().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the 'PSF' column is NaN\n",
    "df = df.dropna(subset=['PSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after removing all the irrelevant data, all the data with no asking price is GONE YAY !\n",
    "nan_counts_per_column = df.isna().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296057f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    return re.sub(\"\\D\",\"\",str(text))\n",
    "df[\"Size\"] = df[\"Size\"].apply(lambda x:clean(x))\n",
    "df[\"District\"] = df[\"District\"].apply(lambda x:clean(x))\n",
    "df[\"Asking Price\"] = df[\"Asking Price\"].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569ce03",
   "metadata": {},
   "source": [
    "# Transforming categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing property types to ints\n",
    "df[\"Property Type\"].replace({\"Apartment\":int(0), \"Condominium\":int(1)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a67647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = pd.to_numeric(df['Age']).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'Tenure' is 'n.a'\n",
    "df = df[df['Tenure'] != 'n.a']\n",
    "# Convert 'Tenure' to numeric; all values appear to be strings of year numbers\n",
    "df['Tenure'] = pd.to_numeric(df['Tenure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881df3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Years_Left'] = df['Tenure'] - df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37667273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that all ammenity elements are dicts\n",
    "def check_same_type(lst):\n",
    "    if not lst:\n",
    "        return False  # Empty list has no type\n",
    "    first_type = type(lst[0])\n",
    "    return all(type(item) == first_type for item in lst[1:])\n",
    "\n",
    "amenities = df['Amenities'].tolist()\n",
    "\n",
    "print(check_same_type(amenities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd33d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each element in the Amenities column to a dict\n",
    "import ast\n",
    "\n",
    "def parse_str_to_dict(string_dict):\n",
    "    parsed_dict = ast.literal_eval(string_dict)\n",
    "    return parsed_dict\n",
    "\n",
    "amenities = list(map(lambda element: parse_str_to_dict(element), df['Amenities'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e94ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to rerun all cells for this to work\n",
    "df_normalized = pd.json_normalize(amenities)\n",
    "df = df.drop('Amenities', axis=1)\n",
    "df_normalized.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = pd.concat([df, df_normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cdde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many Primary schools how many sec schools?\n",
    "df['Primary Schools'] = df['Primary Schools'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "df['Secondary Schools'] = df['Secondary Schools'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "df['Shopping Malls'] = df['Shopping Malls'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "df['Groceries & Supermarts'] = df['Groceries & Supermarts'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"No. of Amenities\"] = df['Primary Schools'] + df['Secondary Schools'] + df['Shopping Malls'] + df['Groceries & Supermarts']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Years_Left'] = df['Tenure'] - df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['No. of Units', 'PSF', 'Tenure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Bedrooms', 'Bathrooms', 'Asking Price', and 'Size' to integer\n",
    "df['Bedrooms'] = pd.to_numeric(df['Bedrooms']).astype('Int64')\n",
    "df['Bathrooms'] = pd.to_numeric(df['Bathrooms']).astype('Int64')\n",
    "df['Asking Price'] = pd.to_numeric(df['Asking Price']).astype('Int64')\n",
    "df['Size'] = pd.to_numeric(df['Size']).astype('Int64')\n",
    "df['Age'] = pd.to_numeric(df['Age']).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking nan values\n",
    "# Check for NaN values in each column\n",
    "nan_counts_per_column = df.isna().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fecc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is stored in a Pandas DataFrame named 'df'\n",
    "# Replace 'df' with the name of your actual DataFrame\n",
    "\n",
    "# Check the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "\n",
    "# Check the data types of each column\n",
    "print(\"Data types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing or NaN values\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"Number of missing values in each column:\")\n",
    "    print(missing_values)\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "\n",
    "# Check for unique values in each column\n",
    "print(\"Unique values in each column:\")\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"{column}: {unique_values}\")\n",
    "\n",
    "# Check summary statistics of the DataFrame\n",
    "print(\"Summary statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Property Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dddd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will take 10 years to run lol\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Function to apply geocoding\n",
    "def geocode_address(addr, geocode):\n",
    "    try:\n",
    "        location = geocode(f\"{addr}, Singapore\")  # Force the context to Singapore in the query\n",
    "        if location and 'Singapore' in location.address:\n",
    "            return pd.Series([location.latitude, location.longitude])\n",
    "        else:\n",
    "            return pd.Series([None, None])\n",
    "    except:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Function to process chunks of addresses\n",
    "def process_addresses(df, chunk_size=1000):\n",
    "    # Initialize the geocoder\n",
    "    geolocator = Nominatim(user_agent=\"NUS_project\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "    \n",
    "    # Number of chunks\n",
    "    num_chunks = (len(df) // chunk_size) + (1 if len(df) % chunk_size != 0 else 0)\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        # Define chunk limits\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = start_idx + chunk_size\n",
    "        \n",
    "        # Process chunk\n",
    "        chunk = df.iloc[start_idx:end_idx]\n",
    "        chunk[['Latitude', 'Longitude']] = chunk['Address'].apply(lambda x: geocode_address(x, geocode))\n",
    "        \n",
    "        # Save results to a CSV file\n",
    "        chunk.to_csv(f'geocoded_addresses_{start_idx}_{end_idx}.csv', index=False)\n",
    "        \n",
    "        print(f\"Processed and saved chunk {i+1}/{num_chunks} (rows {start_idx} to {end_idx})\")\n",
    "\n",
    "# Assuming df is your DataFrame loaded with addresses \n",
    "process_addresses(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
